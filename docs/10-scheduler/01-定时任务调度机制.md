# 定时任务调度机制

> **版本**：V3.0  
> **更新日期**：2025-01-XX  
> **实现状态**：✅ 已实现（生产环境）  
> **决策**：采用 Crontab + HTTP 接口方案，使用自动化脚本和 GitHub Actions 部署

## 概述

系统采用**外部Cron（Crontab）+ 业务HTTP接口 + 自动化脚本**的方式实现定时任务调度。

**架构决策**：经过评估，决定不使用独立的 sync 服务，而是直接使用 Crontab 调用 apiserver 的 REST API 接口。详见 [架构决策文档](./05-架构决策：独立Sync服务vsCrontab.md)。

**核心特性**：

- ✅ **自动 Token 管理**：使用 `refresh-token.sh` 和 `api-call.sh` 脚本自动获取和刷新 Token
- ✅ **统一脚本模板**：所有任务使用 `api-call.sh` 统一处理，简化配置
- ✅ **GitHub Actions 自动部署**：通过 CI/CD 自动部署配置到生产服务器
- ✅ **完善的日志管理**：统一的日志格式和轮转配置

**设计理念**：

- **简单直接**：Crontab直接调用业务接口，无需额外的调度服务层
- **职责清晰**：应用专注于业务逻辑，调度由操作系统负责
- **易于运维**：利用成熟的Cron工具，配置简单，日志清晰
- **自动化部署**：通过 GitHub Actions 实现配置的版本控制和自动部署

## 架构设计

### 任务执行流程

```text
Crontab/Systemd Timer/Kubernetes CronJob
    │
    ▼
直接调用业务HTTP接口
    │
    ▼
业务Handler（PlanHandler/StatisticsHandler等）
    │
    ▼
应用服务层（TaskSchedulerService/SyncService等）
    │
    ▼
执行具体业务逻辑
```

**关键点**：

- 不需要独立的调度服务
- 不需要额外的抽象层
- Crontab直接调用各模块的业务接口

## 使用方式

### 方式一：GitHub Actions 自动部署（推荐）

系统已实现 GitHub Actions 自动部署，推送代码到 `main` 分支即可自动部署到生产服务器。

**详细说明**：参考 [GitHub Actions 自动部署指南](./08-GitHub Actions自动部署.md)

**快速开始**：

1. 配置 GitHub Secrets（SVRA_HOST, SVRA_USERNAME, SVRA_SSH_KEY, IAM_USERNAME, IAM_PASSWORD 等）
2. 推送代码到 `main` 分支（自动触发）
3. 或手动触发：Actions → Deploy Crontab Configuration → Run workflow

### 方式二：手动部署

**详细说明**：参考 [Crontab 配置示例](./06-Crontab配置示例.md) 和 [configs/crontab/README.md](../../../configs/crontab/README.md)

**核心脚本**：

- `api-call.sh` - 通用 API 调用脚本，自动获取 Token 并执行 API 调用
- `refresh-token.sh` - Token 刷新脚本，从 IAM 获取 Token 并存储到本地

**配置示例**：

```bash
# 使用 api-call.sh 脚本（推荐）
0 * * * * root /usr/local/bin/qs-api-call.sh /api/v1/statistics/sync/daily /var/log/qs-scheduler/sync-daily.log
5 * * * * root /usr/local/bin/qs-api-call.sh /api/v1/statistics/sync/accumulated /var/log/qs-scheduler/sync-accumulated.log
```

**Crontab表达式说明**：

```bash
# 格式：分 时 日 月 周 用户 命令
0 * * * * root    # 每小时执行（root 用户）
0 0 * * * root    # 每天0点执行
0 */2 * * * root  # 每2小时执行
0 0 * * 0 root    # 每周日0点执行
```

### 为什么使用Crontab + 自动化脚本？

**设计优势**：

1. **简单直接**：
   - 不需要额外的调度服务层
   - Crontab直接调用业务接口
   - 使用统一脚本模板，配置简洁

2. **自动Token管理**：
   - 脚本自动获取和刷新 Token
   - 无需手动维护 Token
   - 支持 IAM 自动登录

3. **职责清晰**：
   - 应用专注于业务逻辑
   - 调度由操作系统负责
   - 符合单一职责原则

4. **易于运维**：
   - 日志清晰，统一的日志格式
   - 可以随时调整，无需重启应用
   - 支持 GitHub Actions 自动部署

5. **容器友好**：
   - Kubernetes CronJob是标准做法
   - 容器编排工具原生支持
   - 易于监控和告警

## 定时任务列表

### Plan模块

- **调度待推送任务**
  - 描述：扫描待推送任务，生成入口并开放
  - 接口：`POST /api/v1/plans/tasks/schedule`
  - 频率：每小时执行一次（每小时第 20 分）
  - Crontab：`20 * * * * root /usr/local/bin/qs-api-call.sh /api/v1/plans/tasks/schedule /var/log/qs-scheduler/schedule-tasks.log`

### Statistics模块

- **同步每日统计**
  - 描述：将Redis中的每日统计数据同步到MySQL
  - 接口：`POST /api/v1/statistics/sync/daily`
  - 频率：每小时执行一次（每小时第 0 分）
  - Crontab：`0 * * * * root /usr/local/bin/qs-api-call.sh /api/v1/statistics/sync/daily /var/log/qs-scheduler/sync-daily.log`

- **同步累计统计**
  - 描述：将Redis中的累计统计数据同步到MySQL
  - 接口：`POST /api/v1/statistics/sync/accumulated`
  - 频率：每小时执行一次（每小时第 5 分）
  - Crontab：`5 * * * * root /usr/local/bin/qs-api-call.sh /api/v1/statistics/sync/accumulated /var/log/qs-scheduler/sync-accumulated.log`

- **同步计划统计**
  - 描述：同步计划统计数据
  - 接口：`POST /api/v1/statistics/sync/plan`
  - 频率：每小时执行一次（每小时第 10 分）
  - Crontab：`10 * * * * root /usr/local/bin/qs-api-call.sh /api/v1/statistics/sync/plan /var/log/qs-scheduler/sync-plan.log`

- **校验数据一致性**
  - 描述：校验统计数据一致性（Redis vs MySQL）
  - 接口：`POST /api/v1/statistics/validate`
  - 频率：每小时执行一次（每小时第 15 分）
  - Crontab：`15 * * * * root /usr/local/bin/qs-api-call.sh /api/v1/statistics/validate /var/log/qs-scheduler/validate.log`

## 业务接口

所有定时任务都是通过各模块的业务接口调用，无需额外的调度接口：

- `POST /api/v1/plans/tasks/schedule` - 调度待推送任务
- `POST /api/v1/statistics/sync/daily` - 同步每日统计
- `POST /api/v1/statistics/sync/accumulated` - 同步累计统计
- `POST /api/v1/statistics/sync/plan` - 同步计划统计
- `POST /api/v1/statistics/validate` - 校验数据一致性

**注意**：

- 这些接口需要认证，使用 `api-call.sh` 脚本自动处理 Token 获取和刷新
- 推荐使用 IAM 服务账号，通过 `refresh-token.sh` 自动获取 Token
- 所有定时任务都通过 REST API 调用，无需独立的 sync 服务

## 核心脚本

系统提供了两个核心脚本，简化配置和管理：

### `api-call.sh` - 通用 API 调用脚本

**功能**：

- 自动检查 Token 是否存在
- 如果 Token 不存在，自动调用 `refresh-token.sh` 获取
- 使用 Token 执行 API 调用
- 统一的错误处理和日志记录

**使用方式**：

```bash
/usr/local/bin/qs-api-call.sh <endpoint> [log_file]
```

### `refresh-token.sh` - Token 刷新脚本

**功能**：

- 调用 IAM 登录接口获取 Token
- 将 Token 存储到本地文件（`/etc/qs-server/internal-token`）
- 支持多种 Token 格式（token、access_token）

**使用方式**：

```bash
# 由 api-call.sh 自动调用，无需手动执行
/usr/local/bin/qs-refresh-token.sh
```

## 配置文档

详细的配置说明请参考：

- **[configs/crontab/README.md](../../../configs/crontab/README.md)** - 生产环境配置完整指南
- **[Crontab 配置示例](./06-Crontab配置示例.md)** - 配置示例和说明
- **[内部调用 Token 生成指南](./07-内部调用Token生成指南.md)** - Token 生成和管理
- **[GitHub Actions 自动部署](./08-GitHub Actions自动部署.md)** - 自动部署指南

## 添加新任务

添加新的定时任务非常简单：

1. **在应用服务层实现业务逻辑**（如果还没有）：

```go
// internal/apiserver/application/mymodule/my_service.go
func (s *myService) DoScheduledTask(ctx context.Context) error {
    // 业务逻辑
}
```

1. **在Handler中暴露HTTP接口**：

```go
// internal/apiserver/interface/restful/handler/my_handler.go
func (h *MyHandler) DoScheduledTask(c *gin.Context) {
    if err := h.myService.DoScheduledTask(c.Request.Context()); err != nil {
        h.Error(c, err)
        return
    }
    h.Success(c, gin.H{"message": "任务执行完成"})
}
```

1. **在Router中注册路由**：

```go
// internal/apiserver/routers.go
myModule.POST("/scheduled-task", myHandler.DoScheduledTask)
```

1. **配置Crontab**（使用 `api-call.sh` 脚本）：

```bash
# 在 configs/crontab/qs-scheduler 中添加
30 * * * * root /usr/local/bin/qs-api-call.sh /api/v1/mymodule/scheduled-task /var/log/qs-scheduler/my-task.log
```

1. **通过 GitHub Actions 自动部署**：

推送代码到 `main` 分支，GitHub Actions 会自动部署配置。

**就这么简单！** 不需要额外的调度服务层。

## 注意事项

1. **幂等性**：所有定时任务应该是幂等的，重复执行不应产生副作用
2. **错误处理**：任务执行失败应记录日志，不影响其他任务
3. **监控告警**：建议监控任务执行情况，失败时发送告警
4. **性能考虑**：如果任务执行时间较长，考虑异步处理
5. **Token 管理**：使用 IAM 服务账号，配置自动刷新，不要使用永不过期的 Token
6. **日志管理**：配置日志轮转，避免日志文件过大

## 推荐配置

- **开发环境**：手动部署，使用 `api-call.sh` 脚本
- **生产环境**：使用 GitHub Actions 自动部署，配置日志轮转

**总结**：统一使用 Crontab + HTTP接口 + 自动化脚本的方式，简单、可靠、易维护、易部署。
