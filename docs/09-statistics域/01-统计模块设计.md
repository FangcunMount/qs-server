# 统计模块设计（V2）

> **版本**：V2.1  
> **范围**：问卷&量表 BC 中的 statistics 子域  
> **目标**：设计系统级、问卷/量表级、受试者级、计划级的统计能力  
> **更新日期**：2025-01-XX  
> **实现状态**：✅ 已实现（核心功能完成，部分功能待完善）

---

## 1. 结论（3行内）

统计模块采用**三层架构**：**事件驱动增量更新（Redis）** + **定时任务持久化（MySQL统计表）** + **实时查询兜底（原始表聚合）**。事件触发时只写Redis预聚合，定时任务同步到MySQL统计表，查询时优先查统计表，未命中时实时聚合原始表。通过幂等性保证和定时校验确保数据一致性。

---

## 2. 模块职责与边界

### 2.1 子域定位

**statistics 子域关注的核心问题**：

- **系统整体数据统计**：问卷数量、答卷数量、受试者数量、测评总数等全局指标
- **问卷/量表维度统计**：单个问卷的填写总数、近7/15/30天填写趋势、完成率等
- **受试者维度统计**：单个受试者的填写情况、测评结果分布、趋势分析等
- **测评计划维度统计**：计划的完成率、任务执行情况、趋势分析等
- **筛查项目维度统计**：项目的参与率、风险分布、异常名单等

**statistics 子域不关心的问题**：

- "如何计分和解读"：这是 scale 子域的职责
- "如何收集答卷"：这是 survey 子域的职责
- "如何管理测评生命周期"：这是 assessment 子域的职责

### 2.2 核心设计原则

1. **最终一致性**：统计采用最终一致性，允许短暂延迟（秒级）
2. **性能优先**：事件触发时只写Redis，不阻塞主流程
3. **可恢复性**：支持从原始表实时聚合，统计表丢失可重建
4. **幂等性保证**：所有更新操作必须幂等，支持事件重放
5. **可观测性**：统计更新失败不影响主流程，但需要监控告警

---

## 3. 三层架构设计

### 3.1 架构总览

```text
┌─────────────────────────────────────────────────────────────┐
│                    统计查询层（Query Layer）                    │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │ Redis Cache  │→ │ MySQL Stats   │→ │ Raw Tables    │     │
│  │ (查询结果缓存) │  │ (预聚合统计表) │  │ (实时聚合兜底) │     │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
└─────────────────────────────────────────────────────────────┘
                            ↑
┌─────────────────────────────────────────────────────────────┐
│                  统计更新层（Update Layer）                    │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │ Event Handler│→ │ Redis Incr   │→ │ MySQL Stats  │     │
│  │ (事件处理器)  │  │ (实时预聚合)  │  │ (定时同步)    │     │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
└─────────────────────────────────────────────────────────────┘
                            ↑
┌─────────────────────────────────────────────────────────────┐
│                   数据源层（Source Layer）                     │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │ Assessment   │  │ AnswerSheet   │  │ Assessment   │     │
│  │ Submitted    │  │ Interpreted   │  │ Plan/Task    │     │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
└─────────────────────────────────────────────────────────────┘
```

### 3.2 第一层：事件驱动增量更新（Redis）

**职责**：事件触发时实时更新Redis预聚合，不阻塞主流程

**更新策略**：

- 事件触发时：只写Redis，使用 `INCR` 原子操作
- 幂等性保证：使用 `event_id` 作为幂等键
- 数据格式：计数器（整数）或Hash（分布数据）

**Redis键设计**：

```text
# 每日统计（事件触发时递增）
stats:daily:{org_id}:{type}:{key}:{date}          # 每日计数
示例：stats:daily:1:questionnaire:Q001:2025-01-20

# 滑动窗口统计（事件触发时递增，定时清理过期数据）
stats:window:{org_id}:{type}:{key}:{window}       # 近N天计数
示例：stats:window:1:questionnaire:Q001:last7d

# 累计统计（事件触发时递增）
stats:accum:{org_id}:{type}:{key}:{metric}        # 累计指标
示例：stats:accum:1:questionnaire:Q001:total_submissions

# 分布统计（事件触发时更新Hash）
stats:dist:{org_id}:{type}:{key}:{dimension}     # 分布数据
示例：stats:dist:1:questionnaire:Q001:origin_type

# 幂等性标记
event:processed:{event_id}                        # 事件处理标记（TTL=7天）
```

### 3.3 第二层：定时任务持久化（MySQL统计表）

**职责**：定时将Redis预聚合结果同步到MySQL统计表，保证数据持久化

**同步策略**：

- 同步频率：每小时执行一次
- 同步方式：从Redis读取，UPSERT到MySQL
- 数据校验：同步后校验Redis和MySQL数据一致性

**MySQL统计表设计**：

```sql
-- ==================== 1. 每日统计表（时间序列数据） ====================
CREATE TABLE statistics_daily (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    org_id BIGINT NOT NULL COMMENT '机构ID',
    statistic_type VARCHAR(50) NOT NULL COMMENT '统计类型：questionnaire/testee/plan/screening',
    statistic_key VARCHAR(255) NOT NULL COMMENT '统计键（如 questionnaire_code、testee_id）',
    stat_date DATE NOT NULL COMMENT '统计日期',
    
    -- 计数指标
    submission_count BIGINT NOT NULL DEFAULT 0 COMMENT '提交数',
    completion_count BIGINT NOT NULL DEFAULT 0 COMMENT '完成数',
    
    -- 扩展指标（JSON，支持灵活扩展）
    extra_metrics JSON COMMENT '扩展指标：{"risk_distribution": {...}, "origin_distribution": {...}}',
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_org_type_key_date (org_id, statistic_type, statistic_key, stat_date),
    KEY idx_org_date (org_id, stat_date),
    KEY idx_type_key (statistic_type, statistic_key)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='每日统计表';

-- ==================== 2. 累计统计表（维度预聚合） ====================
-- 设计理念：统一表结构，通过 statistic_type 区分不同维度
CREATE TABLE statistics_accumulated (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    org_id BIGINT NOT NULL COMMENT '机构ID',
    statistic_type VARCHAR(50) NOT NULL COMMENT '统计类型：questionnaire/testee/plan/screening/system',
    statistic_key VARCHAR(255) NOT NULL COMMENT '统计键',
    
    -- 基础指标
    total_submissions BIGINT NOT NULL DEFAULT 0 COMMENT '总提交数',
    total_completions BIGINT NOT NULL DEFAULT 0 COMMENT '总完成数',
    
    -- 时间窗口指标（从 statistics_daily 聚合）
    last7d_submissions BIGINT NOT NULL DEFAULT 0 COMMENT '近7天提交数',
    last15d_submissions BIGINT NOT NULL DEFAULT 0 COMMENT '近15天提交数',
    last30d_submissions BIGINT NOT NULL DEFAULT 0 COMMENT '近30天提交数',
    
    -- 分布指标（JSON）
    distribution JSON COMMENT '分布数据：{"risk": {...}, "origin": {...}, "status": {...}}',
    
    -- 时间维度
    first_occurred_at TIMESTAMP NULL COMMENT '首次发生时间',
    last_occurred_at TIMESTAMP NULL COMMENT '最近发生时间',
    
    -- 最后更新时间
    last_updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_org_type_key (org_id, statistic_type, statistic_key),
    KEY idx_org_type (org_id, statistic_type),
    KEY idx_type_key (statistic_type, statistic_key)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='累计统计表';

-- ==================== 3. 计划任务统计表（计划维度专用） ====================
-- 设计理念：计划统计需要关联任务表，单独设计更清晰
CREATE TABLE statistics_plan (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    org_id BIGINT NOT NULL COMMENT '机构ID',
    plan_id BIGINT UNSIGNED NOT NULL COMMENT '计划ID',
    
    -- 任务统计
    total_tasks BIGINT NOT NULL DEFAULT 0 COMMENT '总任务数',
    completed_tasks BIGINT NOT NULL DEFAULT 0 COMMENT '已完成任务数',
    pending_tasks BIGINT NOT NULL DEFAULT 0 COMMENT '待完成任务数',
    expired_tasks BIGINT NOT NULL DEFAULT 0 COMMENT '已过期任务数',
    
    -- 受试者统计
    enrolled_testees BIGINT NOT NULL DEFAULT 0 COMMENT '已加入计划的受试者数',
    active_testees BIGINT NOT NULL DEFAULT 0 COMMENT '活跃受试者数（有完成任务的）',
    
    -- 最后更新时间
    last_updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    UNIQUE KEY uk_plan (org_id, plan_id),
    KEY idx_org_id (org_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='计划统计表';
```

**表设计说明**：

| 表名 | 用途 | 数据来源 | 更新频率 |
|-----|------|---------|---------|
| `statistics_daily` | 每日时间序列数据 | Redis → MySQL | 每小时同步 |
| `statistics_accumulated` | 累计统计（统一表） | Redis + statistics_daily聚合 | 每小时更新 |
| `statistics_plan` | 计划维度统计（专用表） | assessment_tasks表聚合 | 每小时更新 |

### 3.4 第三层：实时查询兜底（原始表聚合）

**职责**：统计表未命中时，实时聚合原始表作为兜底

**查询策略**：

- 优先查Redis缓存（查询结果缓存，TTL=5分钟）
- 其次查MySQL统计表（预聚合数据）
- 最后查原始表实时聚合（assessments、assessment_tasks等）

**原始表聚合查询示例**：

```sql
-- 问卷统计：从 assessments 表聚合
SELECT 
    questionnaire_code,
    COUNT(*) AS total_submissions,
    COUNT(CASE WHEN status = 'interpreted' THEN 1 END) AS total_completions,
    COUNT(CASE WHEN created_at >= DATE_SUB(NOW(), INTERVAL 7 DAY) THEN 1 END) AS last7d_submissions
FROM assessments
WHERE org_id = ? AND questionnaire_code = ?
GROUP BY questionnaire_code;

-- 受试者统计：从 assessments 表聚合
SELECT 
    testee_id,
    COUNT(*) AS total_assessments,
    COUNT(CASE WHEN status = 'interpreted' THEN 1 END) AS completed_assessments,
    MAX(interpreted_at) AS last_assessment_date,
    MIN(created_at) AS first_assessment_date
FROM assessments
WHERE org_id = ? AND testee_id = ?
GROUP BY testee_id;
```

---

## 4. 关键流程设计

### 4.1 事件驱动更新流程

```mermaid
sequenceDiagram
    participant Assessment
    participant EventBus
    participant Handler
    participant Redis
    participant MySQL

    Assessment->>EventBus: Publish(AssessmentSubmittedEvent)
    EventBus->>Handler: Handle(event)
    
    Handler->>Handler: 幂等性检查(event_id)
    alt 已处理
        Handler-->>EventBus: 跳过（已处理）
    else 未处理
        Handler->>Redis: INCR(stats:daily:...)
        Handler->>Redis: INCR(stats:window:...)
        Handler->>Redis: INCR(stats:accum:...)
        Handler->>Redis: HINCRBY(stats:dist:...)
        Handler->>Redis: SET(event:processed:{id}, TTL=7d)
        Handler-->>EventBus: 处理完成
    end
    
    Note over MySQL: 定时任务（每小时）
    MySQL->>Redis: 扫描所有 stats:daily:* 键
    Redis-->>MySQL: 返回每日统计
    MySQL->>MySQL: UPSERT statistics_daily
    MySQL->>MySQL: 聚合更新 statistics_accumulated
```

### 4.2 统计查询流程

```mermaid
sequenceDiagram
    participant Client
    participant AppService
    participant Redis
    participant MySQL
    participant RawTables

    Client->>AppService: GetStatistics(req)
    
    AppService->>Redis: Get(cache_key)
    alt 缓存命中
        Redis-->>AppService: 返回缓存数据
        AppService-->>Client: 返回结果
    else 缓存未命中
        AppService->>MySQL: SELECT FROM statistics_accumulated
        alt 统计表有数据
            MySQL-->>AppService: 返回预聚合数据
            AppService->>Redis: Set(cache_key, TTL=5min)
            AppService-->>Client: 返回结果
        else 统计表无数据
            AppService->>RawTables: 实时聚合查询
            RawTables-->>AppService: 返回聚合结果
            AppService->>Redis: Set(cache_key, TTL=5min)
            AppService-->>MySQL: 异步写入统计表（可选）
            AppService-->>Client: 返回结果
        end
    end
```

### 4.3 定时任务同步流程

```mermaid
sequenceDiagram
    participant Scheduler
    participant Redis
    participant MySQL
    participant Validator

    Note over Scheduler: 每小时执行
    Scheduler->>Redis: SCAN stats:daily:*
    Redis-->>Scheduler: 返回所有每日统计键
    
    loop 每个统计键
        Scheduler->>Redis: GET(key)
        Redis-->>Scheduler: 返回计数值
        Scheduler->>MySQL: UPSERT statistics_daily
    end
    
    Scheduler->>MySQL: 聚合 statistics_daily → statistics_accumulated
    Note over Scheduler: 计算近7/15/30天数据
    
    Scheduler->>Validator: 校验数据一致性
    Validator->>Redis: 读取Redis统计
    Validator->>MySQL: 读取MySQL统计
    Validator->>Validator: 对比差异
    alt 数据不一致
        Validator->>MySQL: 修复统计表（以Redis为准）
    end
```

---

## 5. 统计维度设计

### 5.1 系统整体统计

```go
type SystemStatistics struct {
    OrgID int64
    
    // 基础数量统计
    QuestionnaireCount int64  // 问卷总数（从 questionnaires 表 COUNT）
    AnswerSheetCount   int64  // 答卷总数（从 answer_sheets 表 COUNT，status=submitted）
    TesteeCount        int64  // 受试者总数（从 testees 表 COUNT）
    AssessmentCount    int64  // 测评总数（从 assessments 表 COUNT）
    
    // 状态分布
    AssessmentStatusDistribution map[string]int64 // 按状态统计
    
    // 今日新增（每日凌晨清零）
    TodayNewAssessments    int64 // 今日新增测评
    TodayNewAnswerSheets   int64 // 今日新增答卷
    TodayNewTestees        int64 // 今日新增受试者
    
    // 趋势数据（近30天）
    AssessmentTrend []DailyCount // 每日测评数量趋势
}
```

### 5.2 问卷/量表统计

```go
type QuestionnaireStatistics struct {
    OrgID            int64
    QuestionnaireCode string
    
    // 基础统计
    TotalSubmissions int64   // 总提交数
    TotalCompletions int64   // 总完成数（已解读）
    CompletionRate   float64 // 完成率 = TotalCompletions / TotalSubmissions
    
    // 时间维度统计
    Last7DaysCount   int64  // 近7天提交数
    Last15DaysCount  int64  // 近15天提交数
    Last30DaysCount  int64  // 近30天提交数
    
    // 趋势数据（近30天）
    DailyTrend       []DailyCount // 每日提交趋势
    
    // 来源分布
    OriginDistribution map[string]int64 // 按来源统计（adhoc/plan/screening）
}
```

### 5.3 受试者统计

```go
type TesteeStatistics struct {
    OrgID   int64
    TesteeID uint64
    
    // 测评统计
    TotalAssessments     int64  // 总测评数
    CompletedAssessments int64  // 已完成测评数
    PendingAssessments   int64  // 待完成测评数
    
    // 风险分布
    RiskDistribution     map[string]int64 // 按风险等级统计
    
    // 时间维度
    LastAssessmentDate   *time.Time // 最近测评日期
    FirstAssessmentDate  *time.Time // 首次测评日期
}
```

### 5.4 测评计划统计

```go
type PlanStatistics struct {
    OrgID int64
    PlanID uint64
    
    // 任务统计
    TotalTasks     int64  // 总任务数
    CompletedTasks int64  // 已完成任务数
    PendingTasks   int64  // 待完成任务数
    ExpiredTasks   int64  // 已过期任务数
    
    // 完成率
    CompletionRate float64 // 完成率 = CompletedTasks / TotalTasks
    
    // 受试者统计
    EnrolledTestees int64  // 已加入计划的受试者数
    ActiveTestees   int64  // 活跃受试者数（有完成任务的）
}
```

### 5.5 筛查项目统计

```go
type ScreeningStatistics struct {
    OrgID       int64
    ScreeningID uint64
    
    // 参与统计
    TotalParticipants    int64  // 总参与人数
    CompletedParticipants int64  // 已完成人数
    ParticipationRate    float64 // 参与率 = TotalParticipants / TargetParticipants
    
    // 风险分布
    RiskDistribution     map[string]int64 // 按风险等级统计
    
    // 目标人数
    TargetParticipants   int64  // 目标参与人数
}
```

---

## 6. 核心组件设计

### 6.1 应用服务层

| 服务 | 职责 | 查询策略 |
|-----|------|---------|
| `SystemStatisticsService` | 系统整体统计 | Redis缓存 → statistics_accumulated → 原始表聚合 |
| `QuestionnaireStatisticsService` | 问卷/量表统计 | Redis缓存 → statistics_accumulated → assessments表聚合 |
| `TesteeStatisticsService` | 受试者统计 | Redis缓存 → statistics_accumulated → assessments表聚合 |
| `PlanStatisticsService` | 计划统计 | Redis缓存 → statistics_plan → assessment_tasks表聚合 |
| `ScreeningStatisticsService` | 筛查项目统计 | Redis缓存 → statistics_accumulated → assessments表聚合 |

### 6.2 领域服务层

| 服务 | 职责 |
|-----|------|
| `StatisticsAggregator` | 统计聚合器，封装统计计算逻辑 |
| `TrendAnalyzer` | 趋势分析器，计算时间序列趋势 |
| `StatisticsValidator` | 统计校验器，校验Redis和MySQL数据一致性 |

### 6.3 基础设施层

| 组件 | 职责 |
|-----|------|
| `StatisticsRepository` | 统计查询仓储（MySQL统计表查询） |
| `StatisticsCache` | 统计缓存（Redis操作封装） |
| `StatisticsEventHandler` | 领域事件处理器（订阅事件，更新Redis） |
| `StatisticsSyncService` | 统计同步服务（定时任务，Redis → MySQL） |
| `StatisticsValidatorService` | 统计校验服务（定时任务，数据一致性校验） |

---

## 7. 关键设计决策

### 7.1 统一累计统计表设计

**决策**：使用统一的 `statistics_accumulated` 表存储所有维度的累计统计，通过 `statistic_type` 区分维度。

**原因**：

- 减少表数量，简化维护
- 统一的查询接口，易于扩展
- 通过索引优化查询性能

**实现**：

```sql
-- 问卷统计
INSERT INTO statistics_accumulated (org_id, statistic_type, statistic_key, ...)
VALUES (1, 'questionnaire', 'Q001', ...);

-- 受试者统计
INSERT INTO statistics_accumulated (org_id, statistic_type, statistic_key, ...)
VALUES (1, 'testee', '123', ...);
```

### 7.2 事件处理幂等性

**决策**：所有事件处理必须幂等，使用 `event_id` 作为幂等键。

**实现**：

```go
func (h *EventHandler) Handle(ctx context.Context, event Event) error {
    // 幂等性检查
    idempotencyKey := fmt.Sprintf("event:processed:%s", event.ID())
    if exists, _ := cache.Exists(ctx, idempotencyKey); exists {
        return nil // 已处理，跳过
    }
    
    // 处理事件（更新Redis）
    if err := h.updateRedis(ctx, event); err != nil {
        return err
    }
    
    // 标记已处理（TTL=7天）
    cache.Set(ctx, idempotencyKey, "1", 7*24*time.Hour)
    return nil
}
```

### 7.3 数据一致性保证

**决策**：采用最终一致性，通过定时校验修复不一致。

**策略**：

1. **事件驱动更新**：事件触发时只写Redis，保证实时性
2. **定时同步**：每小时将Redis同步到MySQL，保证持久化
3. **定时校验**：每小时校验Redis和MySQL数据一致性，修复差异
4. **兜底查询**：统计表未命中时实时聚合原始表

**校验逻辑**：

```go
func (v *ValidatorService) Validate(ctx context.Context) error {
    // 1. 从Redis读取统计
    redisStats := v.cache.GetStatistics(ctx, type, key)
    
    // 2. 从MySQL读取统计
    mysqlStats := v.repo.GetStatistics(ctx, type, key)
    
    // 3. 对比差异
    if redisStats.TotalSubmissions != mysqlStats.TotalSubmissions {
        // 4. 修复MySQL（以Redis为准）
        v.repo.UpdateStatistics(ctx, type, key, redisStats)
    }
    
    return nil
}
```

---

## 8. 实现总结

### 8.1 实现状态概览

**核心功能**：✅ 已实现  
**事件驱动更新**：✅ 已实现  
**定时任务同步**：✅ 已实现  
**数据一致性校验**：✅ 已实现  
**筛查统计服务**：❌ 未实现（仅接口定义）

### 8.2 已实现功能清单

#### 8.2.1 应用服务层

| 服务 | 状态 | 说明 |
|-----|------|------|
| `SystemStatisticsService` | ✅ 部分实现 | 已实现实时聚合查询，缺少预聚合逻辑 |
| `QuestionnaireStatisticsService` | ✅ 完整实现 | 支持三层查询策略，包含趋势分析 |
| `TesteeStatisticsService` | ✅ 完整实现 | 支持三层查询策略，包含风险分布 |
| `PlanStatisticsService` | ✅ 完整实现 | 支持三层查询策略，从任务表聚合 |
| `ScreeningStatisticsService` | ❌ 未实现 | 仅接口定义，待实现 |
| `StatisticsSyncService` | ✅ 完整实现 | 支持每日/累计/计划统计同步 |
| `StatisticsValidatorService` | ✅ 完整实现 | 支持Redis和MySQL数据一致性校验 |

#### 8.2.2 领域层

| 组件 | 状态 | 说明 |
|-----|------|------|
| `Aggregator` | ✅ 完整实现 | 完成率、参与率、时间窗口计算 |
| `TrendAnalyzer` | ✅ 完整实现 | 趋势分析、最近N天数据提取 |
| `Validator` | ⚠️ 部分实现 | 接口定义完整，具体比较逻辑待完善 |
| `Types` | ✅ 完整实现 | 所有统计类型定义完整 |

#### 8.2.3 基础设施层

| 组件 | 状态 | 说明 |
|-----|------|------|
| `StatisticsCache` | ✅ 完整实现 | Redis操作封装，支持每日/窗口/累计/分布统计 |
| `StatisticsRepository` | ✅ 完整实现 | MySQL统计表CRUD，支持聚合查询 |
| `StatisticsDailyPO` | ✅ 完整实现 | 每日统计持久化对象 |
| `StatisticsAccumulatedPO` | ✅ 完整实现 | 累计统计持久化对象 |
| `StatisticsPlanPO` | ✅ 完整实现 | 计划统计持久化对象 |

#### 8.2.4 事件处理

| 事件 | 状态 | 说明 |
|-----|------|------|
| `AssessmentSubmitted` | ✅ 已实现 | 更新问卷/受试者提交统计，支持幂等性 |
| `AssessmentInterpreted` | ✅ 已实现 | 更新问卷/受试者完成统计和风险分布 |

#### 8.2.5 REST API

| 接口 | 状态 | 路径 |
|-----|------|------|
| 系统统计查询 | ✅ 已实现 | `GET /api/v1/statistics/system` |
| 问卷统计查询 | ✅ 已实现 | `GET /api/v1/statistics/questionnaires/:code` |
| 受试者统计查询 | ✅ 已实现 | `GET /api/v1/statistics/testees/:testee_id` |
| 计划统计查询 | ✅ 已实现 | `GET /api/v1/statistics/plans/:plan_id` |
| 同步每日统计 | ✅ 已实现 | `POST /api/v1/statistics/sync/daily` |
| 同步累计统计 | ✅ 已实现 | `POST /api/v1/statistics/sync/accumulated` |
| 同步计划统计 | ✅ 已实现 | `POST /api/v1/statistics/sync/plan` |
| 校验数据一致性 | ✅ 已实现 | `POST /api/v1/statistics/validate` |

#### 8.2.6 定时任务

| 任务 | 状态 | 调度时间 | 说明 |
|-----|------|---------|------|
| 同步每日统计 | ✅ 已配置 | 每小时第0分 | Redis → MySQL |
| 同步累计统计 | ✅ 已配置 | 每小时第5分 | Redis → MySQL |
| 同步计划统计 | ✅ 已配置 | 每小时第10分 | 从任务表聚合 |
| 校验数据一致性 | ✅ 已配置 | 每小时第15分 | Redis vs MySQL |

### 8.3 实现细节说明

#### 8.3.1 查询策略实现

所有统计服务均实现了三层查询策略：

1. **Redis缓存查询**（TTL=5分钟）
   - 缓存键格式：`stats:query:{type}:{org_id}:{key}`
   - 命中时直接返回，避免重复计算

2. **MySQL统计表查询**
   - 优先查询 `statistics_accumulated` 表
   - 计划统计查询 `statistics_plan` 表
   - 趋势数据从 `statistics_daily` 表聚合

3. **原始表实时聚合兜底**
   - 统计表未命中时，从 `assessment`、`assessment_task` 等原始表聚合
   - 结果缓存到Redis，避免重复计算

#### 8.3.2 事件驱动更新实现

**事件处理器位置**：`internal/worker/handlers/statistics_handler.go`

**处理流程**：

1. 幂等性检查：使用 `event:processed:{event_id}` 键（TTL=7天）
2. Redis预聚合：使用原子操作（INCR、HINCRBY）更新统计
3. 标记已处理：防止重复处理

**支持的统计更新**：

- 每日统计：`stats:daily:{org_id}:{type}:{key}:{date}`
- 滑动窗口：`stats:window:{org_id}:{type}:{key}:{window}`
- 累计统计：`stats:accum:{org_id}:{type}:{key}:{metric}`
- 分布统计：`stats:dist:{org_id}:{type}:{key}:{dimension}`

#### 8.3.3 定时同步实现

**同步服务位置**：`internal/apiserver/application/statistics/sync_service.go`

**同步策略**：

1. **每日统计同步**：扫描Redis所有 `stats:daily:*` 键，UPSERT到MySQL
2. **累计统计同步**：从 `statistics_daily` 表聚合到 `statistics_accumulated` 表
3. **计划统计同步**：从 `assessment_task` 表实时聚合，写入 `statistics_plan` 表

**定时任务配置**：`configs/crontab/qs-scheduler`

- 使用 `api-call.sh` 脚本调用REST API
- 支持Token自动刷新
- 日志输出到 `/data/logs/crontab/`

#### 8.3.4 数据一致性校验实现

**校验服务位置**：`internal/apiserver/application/statistics/validator_service.go`

**校验策略**：

1. 扫描Redis所有统计键
2. 对比Redis和MySQL的累计统计值
3. 发现不一致时，以Redis为准修复MySQL

### 8.4 已知问题与待完善功能

#### 8.4.1 系统统计服务

**问题**：目前主要依赖实时聚合，缺少预聚合逻辑

**影响**：查询性能可能较差，特别是数据量大时

**解决方案**：

- 实现系统统计的Redis预聚合
- 在事件处理时更新系统级统计
- 完善 `statistics_accumulated` 表中 `statistic_type='system'` 的记录

#### 8.4.2 筛查统计服务

**问题**：仅接口定义，未实现具体逻辑

**影响**：无法查询筛查项目统计

**解决方案**：

- 实现 `ScreeningStatisticsService`
- 参考 `PlanStatisticsService` 的实现模式
- 从 `assessments` 表聚合筛查相关数据

#### 8.4.3 事件数据字段缺失

**问题**：

- `AssessmentSubmitted` 事件缺少 `origin_type` 字段
- `AssessmentInterpreted` 事件缺少 `questionnaire_code` 字段

**影响**：

- 无法统计来源分布（adhoc/plan/screening）
- 无法在解读事件中更新问卷统计

**解决方案**：

- 在事件Payload中添加缺失字段
- 更新事件处理器，使用新字段更新统计

#### 8.4.4 趋势数据为空

**问题**：系统统计的 `AssessmentTrend` 字段始终为空

**影响**：无法展示系统级趋势图表

**解决方案**：

- 从 `statistics_daily` 表查询系统级趋势
- 或实现系统统计的每日统计更新逻辑

#### 8.4.5 校验器实现不完整

**问题**：`domain/statistics/validator.go` 中的 `ValidateConsistency` 方法未实现具体逻辑

**影响**：领域层校验器无法使用（应用层校验器已实现）

**解决方案**：

- 完善领域层校验器实现
- 或移除未使用的领域层校验器

### 8.5 代码质量与架构符合度

**架构符合度**：✅ 高度符合设计文档

- 三层架构（Redis + MySQL + 原始表）已完整实现
- 事件驱动更新机制已实现
- 定时任务同步机制已实现
- 数据一致性校验机制已实现

**代码组织**：✅ 符合DDD分层架构

- 应用服务层：业务逻辑封装完整
- 领域层：领域模型和计算逻辑清晰
- 基础设施层：数据访问和缓存操作封装良好

**可维护性**：✅ 良好

- 代码结构清晰，职责分离明确
- 接口定义完整，易于扩展
- 错误处理和日志记录完善

---

## 9. 实现路径（更新）

### 9.1 阶段一：核心统计查询（P0）✅ 已完成

**完成时间**：2025-01-XX

**实现内容**：

1. ✅ 实现 `StatisticsRepository`：MySQL统计表查询
2. ✅ 实现 `SystemStatisticsService`：系统整体统计（实时聚合）
3. ✅ 实现 `QuestionnaireStatisticsService`：问卷/量表统计
4. ✅ 实现 `TesteeStatisticsService`：受试者统计
5. ✅ 实现 `PlanStatisticsService`：计划统计
6. ✅ 提供 REST API 接口

**待完善**：

- 系统统计的预聚合逻辑
- 筛查统计服务实现

### 9.2 阶段二：事件驱动更新（P0）✅ 已完成

**完成时间**：2025-01-XX

**实现内容**：

1. ✅ 实现事件处理器：`statistics_handler.go`
2. ✅ 实现 `StatisticsCache`：Redis操作封装
3. ✅ 实现幂等性检查机制
4. ✅ 实现Redis预聚合逻辑

**待完善**：

- 事件数据字段补充（origin_type、questionnaire_code）
- 系统统计的事件更新

### 9.3 阶段三：定时任务同步（P0）✅ 已完成

**完成时间**：2025-01-XX

**实现内容**：

1. ✅ 创建MySQL统计表（migration：`000005_init_statistics_schema.up.sql`）
2. ✅ 实现 `StatisticsSyncService`：Redis → MySQL同步
3. ✅ 实现定时任务调度（crontab配置）
4. ✅ 实现数据校验逻辑

### 9.4 阶段四：完善统计维度（P1）⚠️ 部分完成

**完成时间**：2025-01-XX

**实现内容**：

1. ✅ 实现 `TesteeStatisticsService`（完整实现）
2. ✅ 实现 `PlanStatisticsService`（完整实现）
3. ❌ 实现 `ScreeningStatisticsService`（未实现）
4. ✅ 实现趋势分析功能（`TrendAnalyzer`）

**待完善**：

- 筛查统计服务实现

### 9.5 阶段五：性能优化（P2）✅ 部分完成

**完成时间**：2025-01-XX

**实现内容**：

1. ✅ MySQL索引已优化（迁移文件中已定义）
2. ✅ 实现查询结果缓存（Redis，TTL=5分钟）
3. ✅ 实现实时聚合兜底（原始表聚合）

**待完善**：

- 监控与告警（需要集成监控系统）
- 系统统计的预聚合优化

---

## 10. 代码结构（实际实现）

### 8.1 阶段一：核心统计查询（P0）

**目标**：实现基础统计查询能力

1. 实现 `StatisticsRepository`：MySQL统计表查询
2. 实现 `SystemStatisticsService`：系统整体统计
3. 实现 `QuestionnaireStatisticsService`：问卷/量表统计
4. 提供 REST API 接口

**预计工作量**：3-5 天

### 8.2 阶段二：事件驱动更新（P0）

**目标**：通过事件实时更新Redis统计

1. 实现 `StatisticsEventHandler`：订阅领域事件
2. 实现 `StatisticsCache`：Redis操作封装
3. 实现幂等性检查机制
4. 实现Redis预聚合逻辑

**预计工作量**：3-5 天

### 8.3 阶段三：定时任务同步（P0）

**目标**：定时将Redis同步到MySQL统计表

1. 创建MySQL统计表（migration）
2. 实现 `StatisticsSyncService`：Redis → MySQL同步
3. 实现定时任务调度
4. 实现数据校验逻辑

**预计工作量**：3-5 天

### 8.4 阶段四：完善统计维度（P1）

**目标**：完善所有统计维度

1. 实现 `TesteeStatisticsService`（扩展已有）
2. 实现 `PlanStatisticsService`
3. 实现 `ScreeningStatisticsService`
4. 实现趋势分析功能

**预计工作量**：3-5 天

### 8.5 阶段五：性能优化（P2）

**目标**：优化查询性能，支持高并发

1. 优化MySQL索引
2. 实现查询结果缓存
3. 实现实时聚合兜底
4. 监控与告警

**预计工作量**：2-3 天

---

## 10. 代码结构（实际实现）

```text
internal/apiserver/
├── application/
│   └── statistics/
│       ├── system_service.go          # ✅ 系统统计服务（实时聚合）
│       ├── questionnaire_service.go   # ✅ 问卷统计服务（完整实现）
│       ├── testee_service.go         # ✅ 受试者统计服务（完整实现）
│       ├── plan_service.go           # ✅ 计划统计服务（完整实现）
│       ├── sync_service.go           # ✅ 统计同步服务（定时任务）
│       ├── validator_service.go      # ✅ 统计校验服务（定时任务）
│       ├── interfaces.go            # ✅ 服务接口定义
│       ├── constants.go              # ✅ 全局常量定义
│       └── utils.go                  # ✅ 工具函数
├── domain/
│   └── statistics/
│       ├── aggregator.go             # ✅ 统计聚合器（完整实现）
│       ├── trend_analyzer.go         # ✅ 趋势分析器（完整实现）
│       ├── validator.go              # ⚠️ 统计校验器（接口定义，逻辑待完善）
│       └── types.go                  # ✅ 统计类型定义（完整实现）
└── infra/
    ├── mysql/
    │   └── statistics/
    │       ├── repository.go          # ✅ 统计仓储实现（MySQL）
    │       └── po.go                  # ✅ 持久化对象定义
    └── statistics/
        └── cache.go                   # ✅ 统计缓存实现（Redis）

internal/worker/
└── handlers/
    └── statistics_handler.go         # ✅ 事件处理器（AssessmentSubmitted/Interpreted）

internal/apiserver/
├── interface/
│   └── restful/
│       └── handler/
│           └── statistics.go         # ✅ REST API处理器
└── container/
    └── assembler/
        └── statistics.go             # ✅ 模块组装器

internal/pkg/migration/migrations/mysql/
└── 000005_init_statistics_schema.up.sql  # ✅ 数据库迁移文件

configs/
└── crontab/
    └── qs-scheduler                   # ✅ 定时任务配置
```

**说明**：

- ✅ 表示已完整实现
- ⚠️ 表示部分实现或待完善
- ❌ 表示未实现（筛查统计服务仅接口定义）

---

## 11. 风险点 & 取舍

### 10.1 实时性 vs 性能

**风险**：实时聚合查询在高并发场景下可能成为性能瓶颈。

**取舍**：

- ✅ **高频统计**：Redis预聚合 + MySQL统计表，查询时直接读取
- ✅ **低频统计**：实时聚合原始表，结果缓存5分钟
- ✅ **历史趋势**：从 `statistics_daily` 表查询，无需实时聚合

### 10.2 数据一致性

**风险**：事件丢失或处理失败导致统计不准确。

**取舍**：

- ✅ **最终一致性**：允许短暂延迟（秒级），通过定时校验修复
- ✅ **幂等性保证**：事件处理器必须幂等，支持重复消费
- ✅ **补偿机制**：定时任务每小时全量校验，修复不一致

### 10.3 存储选型

**风险**：统计查询需要跨多个表JOIN，MySQL性能可能不足。

**取舍**：

- ✅ **MySQL为主**：利用统计表预聚合，减少JOIN查询
- ✅ **Redis为辅**：高频统计使用Redis预聚合，减少MySQL压力
- ✅ **原始表兜底**：统计表未命中时实时聚合，保证可用性
- ⚠️ **不引入OLAP**：当前数据量下，MySQL + Redis足够，避免过度设计

### 10.4 表设计统一性

**风险**：多个统计表设计不统一，维护成本高。

**取舍**：

- ✅ **统一累计表**：使用 `statistics_accumulated` 统一存储所有维度累计统计
- ✅ **专用表补充**：计划统计需要关联任务表，单独设计 `statistics_plan`
- ✅ **每日统计表**：时间序列数据统一存储在 `statistics_daily`

---

## 12. 后续优化方向

1. **OLAP集成**：数据量达到百万级后，考虑引入ClickHouse或StarRocks
2. **实时大屏**：基于WebSocket推送实时统计更新
3. **自定义报表**：支持用户自定义统计维度和时间窗口
4. **数据导出**：支持导出统计报表（Excel、PDF）
5. **统计快照**：存储某个时间点的完整统计快照，便于对比分析

---

---

## 13. 附录

### 13.1 关键文件路径

| 文件类型 | 路径 | 说明 |
|---------|------|------|
| 应用服务 | `internal/apiserver/application/statistics/` | 统计服务实现 |
| 领域模型 | `internal/apiserver/domain/statistics/` | 统计领域模型 |
| 基础设施 | `internal/apiserver/infra/statistics/` | Redis缓存封装 |
| MySQL仓储 | `internal/apiserver/infra/mysql/statistics/` | MySQL数据访问 |
| 事件处理 | `internal/worker/handlers/statistics_handler.go` | 事件处理器 |
| REST API | `internal/apiserver/interface/restful/handler/statistics.go` | API处理器 |
| 数据库迁移 | `internal/pkg/migration/migrations/mysql/000005_init_statistics_schema.up.sql` | 表结构定义 |
| 定时任务 | `configs/crontab/qs-scheduler` | Crontab配置 |

### 13.2 Redis键命名规范

| 键类型 | 格式 | 示例 |
|-------|------|------|
| 每日统计 | `stats:daily:{org_id}:{type}:{key}:{date}` | `stats:daily:1:questionnaire:Q001:2025-01-20` |
| 滑动窗口 | `stats:window:{org_id}:{type}:{key}:{window}` | `stats:window:1:questionnaire:Q001:last7d` |
| 累计统计 | `stats:accum:{org_id}:{type}:{key}:{metric}` | `stats:accum:1:questionnaire:Q001:total_submissions` |
| 分布统计 | `stats:dist:{org_id}:{type}:{key}:{dimension}` | `stats:dist:1:questionnaire:Q001:origin` |
| 幂等性标记 | `event:processed:{event_id}` | `event:processed:evt_123456` |
| 查询缓存 | `stats:query:{cache_key}` | `stats:query:questionnaire:1:Q001` |

### 13.3 数据库表结构

| 表名 | 用途 | 主要字段 |
|-----|------|---------|
| `statistics_daily` | 每日时间序列数据 | `org_id`, `statistic_type`, `statistic_key`, `stat_date`, `submission_count`, `completion_count` |
| `statistics_accumulated` | 累计统计（统一表） | `org_id`, `statistic_type`, `statistic_key`, `total_submissions`, `total_completions`, `last7d_submissions` |
| `statistics_plan` | 计划统计（专用表） | `org_id`, `plan_id`, `total_tasks`, `completed_tasks`, `enrolled_testees` |

### 13.4 事件订阅配置

事件处理器在 `configs/events.yaml` 中配置：

```yaml
# AssessmentSubmitted 事件
- name: AssessmentSubmitted
  handlers:
    - statistics-service  # 更新统计

# AssessmentInterpreted 事件
- name: AssessmentInterpreted
  handlers:
    - statistics-service  # 更新统计
```

---

**本文档作为统计模块设计的蓝图和实现总结，后续优化和扩展均以此为准。**
