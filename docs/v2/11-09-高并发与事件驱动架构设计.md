# 13-01 高并发、缓存策略与事件驱动架构设计

> **版本**：V2.0  
> **文档类型**：架构设计 - 性能与并发专题  
> **适用范围**：问卷&量表测评系统（qs-apiserver + qs-worker + collection-server）  
> **最后更新**：2025-11-20

---

## 目录

1. [概述](#1-概述)
2. [事件驱动架构](#2-事件驱动架构)
3. [异步评估设计](#3-异步评估设计)
4. [缓存策略](#4-缓存策略)
5. [查询优化：短轮询到长轮询演进](#5-查询优化短轮询到长轮询演进)
6. [消息队列在高并发中的作用](#6-消息队列在高并发中的作用)
7. [容量规划与扩展](#7-容量规划与扩展)
8. [监控与告警](#8-监控与告警)

---

## 1. 概述

### 1.1 背景

问卷&量表测评系统在实际运营中会面临以下高并发场景：

- **入校筛查**：短时间内数百至数千名家长集中扫码填写问卷
- **周期性测评**：定时推送大批量测评任务
- **突发流量**：营销活动、合作机构批量推广

这些场景对系统的**并发处理能力**、**响应速度**和**稳定性**提出了挑战。

### 1.2 设计目标

**Phase 1（当前阶段）**：
- 整体 QPS：200
- 同时在线用户：数百人
- 单次评估耗时：P95 < 3秒
- 可用性：99.5%

**Phase 2（中期目标）**：
- 整体 QPS：1000+
- 同时等待解析用户：数千人
- /status 查询 QPS：5000+
- 可用性：99.9%

**Phase 3（远期愿景）**：
- 整体 QPS：5000+
- 实时推送机制
- 多地域部署
- 可用性：99.95%

### 1.3 核心设计原则

1. **异步解耦**：提交与处理分离，提高吞吐量
2. **事件驱动**：通过领域事件实现松耦合
3. **缓存优先**：热数据前置，降低数据库压力
4. **渐进演进**：从简单方案起步，预留扩展接口
5. **可观测性**：完善的监控和链路追踪

---

## 2. 事件驱动架构

### 2.1 核心理念

采用 **事件驱动架构（Event-Driven Architecture, EDA）** 来实现服务间的异步通信和业务流程解耦。

**关键优势**：
- 服务解耦：生产者和消费者独立演进
- 弹性伸缩：消费者可根据负载动态扩缩容
- 容错能力：消息队列提供缓冲和重试机制
- 审计追踪：事件流天然形成审计日志

### 2.2 领域事件设计

#### 核心事件

```go
// 答卷提交事件
type AssessmentSubmittedEvent struct {
    EventID       string    `json:"event_id"`      // 事件唯一ID
    AssessmentID  int64     `json:"assessment_id"` // 测评ID
    TesteeID      int64     `json:"testee_id"`     // 受试者ID
    QuestionnaireID int64   `json:"questionnaire_id"`
    MedicalScaleID  *int64  `json:"medical_scale_id,omitempty"`
    OriginType    string    `json:"origin_type"`   // adhoc/plan/screening
    OriginID      *int64    `json:"origin_id,omitempty"`
    SubmittedAt   time.Time `json:"submitted_at"`
    SubmittedBy   int64     `json:"submitted_by"`  // 提交人UserID
}

// 评估完成事件
type AssessmentInterpretedEvent struct {
    EventID       string    `json:"event_id"`
    AssessmentID  int64     `json:"assessment_id"`
    TesteeID      int64     `json:"testee_id"`
    TotalScore    float64   `json:"total_score"`
    RiskLevel     string    `json:"risk_level"`    // low/medium/high
    FactorScores  []FactorScoreDTO `json:"factor_scores"`
    InterpretedAt time.Time `json:"interpreted_at"`
    Duration      int64     `json:"duration_ms"`   // 评估耗时（毫秒）
}

// 评估失败事件
type AssessmentFailedEvent struct {
    EventID      string    `json:"event_id"`
    AssessmentID int64     `json:"assessment_id"`
    ErrorCode    string    `json:"error_code"`
    ErrorMessage string    `json:"error_message"`
    FailedAt     time.Time `json:"failed_at"`
    Retryable    bool      `json:"retryable"`
}
```

#### 事件发布接口

```go
// EventBus 事件总线接口
type EventBus interface {
    // 发布事件到指定 Topic
    Publish(ctx context.Context, topic string, event interface{}) error
    
    // 订阅事件
    Subscribe(topic string, channel string, handler EventHandler) error
    
    // 关闭
    Close() error
}

// EventHandler 事件处理器
type EventHandler interface {
    Handle(ctx context.Context, event interface{}) error
}
```

### 2.3 消息队列配置

#### NSQ Topic/Channel 设计

```yaml
topics:
  - name: assessment_events
    channels:
      - evaluation      # 评估worker消费
      - notification    # 通知worker消费
      - analytics       # 数据分析worker消费（可选）
      
  - name: plan_events
    channels:
      - task_scheduler  # 任务调度器消费
      
  - name: screening_events
    channels:
      - stats_collector # 统计收集器消费
```

#### 消息持久化与可靠性

```go
// NSQ Producer 配置
config := nsq.NewConfig()
config.MaxInFlight = 200                  // 最大并发处理数
config.DefaultRequeueDelay = 30 * time.Second
config.MaxRequeueDelay = 5 * time.Minute
config.MaxAttempts = 3                    // 最大重试次数

// 消息发送
producer.Publish("assessment_events", eventData)
```

---

## 3. 异步评估设计

### 3.1 提交即返回模式

**设计思路**：
答卷提交后立即返回，评估过程完全异步化，避免阻塞用户请求。

**流程图**：

```
[小程序] 
    ↓ POST /api/v1/assessments/submit
[collection-server]
    ↓ 转发
[qs-apiserver]
    ├─→ 1. 校验 AnswerSheet 合法性
    ├─→ 2. 保存 AnswerSheet (MongoDB)
    ├─→ 3. 创建 Assessment (status=submitted, MySQL)
    ├─→ 4. 发布 AssessmentSubmittedEvent (NSQ)
    └─→ 5. HTTP 202 Accepted 立即返回
         ↓
[小程序] 跳转到"解析中"等待页
    ↓ 短轮询 GET /api/v1/assessments/{id}/status
[qs-apiserver]
    └─→ 查询 Assessment.status 返回
    
--- 异步处理线 ---

[qs-worker] 消费 AssessmentSubmittedEvent
    ├─→ 1. 加载 Questionnaire/AnswerSheet/MedicalScale
    ├─→ 2. 调用 Evaluator 职责链
    ├─→ 3. 生成 EvaluationResult
    ├─→ 4. 持久化：
    │      - 更新 Assessment (status=interpreted, total_score, risk_level)
    │      - 保存 AssessmentScore (各因子分)
    │      - 生成 InterpretReport (MongoDB)
    ├─→ 5. 发布 AssessmentInterpretedEvent
    └─→ 6. （可选）更新 Redis 缓存

[notification-worker] 消费 AssessmentInterpretedEvent
    └─→ 发送微信订阅消息/站内通知
```

### 3.2 qs-worker 实现

```go
// EvaluationConsumer 评估消费者
type EvaluationConsumer struct {
    // repositories
    assessmentRepo    AssessmentRepository
    questionnaireRepo QuestionnaireRepository
    answerSheetRepo   AnswerSheetRepository
    scaleRepo         MedicalScaleRepository
    scoreRepo         AssessmentScoreRepository
    reportRepo        InterpretReportRepository
    
    // services
    evaluator     Evaluator
    reportFactory ReportFactory
    eventBus      EventBus
    statusCache   StatusCache  // Redis缓存（可选）
    
    logger *zap.Logger
}

func (c *EvaluationConsumer) Handle(msg *nsq.Message) error {
    var event AssessmentSubmittedEvent
    if err := json.Unmarshal(msg.Body, &event); err != nil {
        return err // NSQ 会重试
    }
    
    ctx := context.Background()
    startTime := time.Now()
    
    // 1. 加载数据
    assessment, err := c.assessmentRepo.FindByID(ctx, event.AssessmentID)
    if err != nil {
        return fmt.Errorf("load assessment: %w", err)
    }
    
    // 如果没有绑定量表，跳过评估
    if assessment.MedicalScaleID == nil {
        c.logger.Info("skip evaluation for survey-only assessment",
            zap.Int64("assessment_id", event.AssessmentID))
        return nil
    }
    
    questionnaire, _ := c.questionnaireRepo.FindByID(ctx, event.QuestionnaireID)
    answerSheet, _ := c.answerSheetRepo.FindByID(ctx, assessment.AnswerSheetID)
    scale, _ := c.scaleRepo.FindByID(ctx, *assessment.MedicalScaleID)
    
    // 2. 执行评估（职责链）
    result, err := c.evaluator.Evaluate(ctx, scale, questionnaire, answerSheet)
    if err != nil {
        // 标记评估失败
        assessment.MarkFailed(err.Error())
        c.assessmentRepo.Save(ctx, assessment)
        
        // 发布失败事件
        c.eventBus.Publish(ctx, "assessment_events", AssessmentFailedEvent{
            EventID:      uuid.New().String(),
            AssessmentID: event.AssessmentID,
            ErrorMessage: err.Error(),
            FailedAt:     time.Now(),
            Retryable:    isRetryableError(err),
        })
        
        return err // 触发 NSQ 重试
    }
    
    // 3. 持久化结果
    assessment.ApplyEvaluation(result.TotalScore, result.RiskLevel)
    assessment.MarkInterpreted(time.Now())
    if err := c.assessmentRepo.Save(ctx, assessment); err != nil {
        return fmt.Errorf("save assessment: %w", err)
    }
    
    // 4. 保存因子分
    scores := mapToAssessmentScores(assessment.ID, result.FactorScores)
    if err := c.scoreRepo.BatchSave(ctx, scores); err != nil {
        c.logger.Error("save scores failed", zap.Error(err))
    }
    
    // 5. 生成解读报告
    report := c.reportFactory.Build(assessment, scale, result)
    if err := c.reportRepo.Save(ctx, report); err != nil {
        return fmt.Errorf("save report: %w", err)
    }
    
    // 6. 更新缓存（如果启用）
    if c.statusCache != nil {
        c.statusCache.Set(ctx, assessment.ID, &StatusSummary{
            Status:     "interpreted",
            TotalScore: &result.TotalScore,
            RiskLevel:  &result.RiskLevel,
        }, 2*time.Hour)
    }
    
    // 7. 发布完成事件
    duration := time.Since(startTime).Milliseconds()
    c.eventBus.Publish(ctx, "assessment_events", AssessmentInterpretedEvent{
        EventID:       uuid.New().String(),
        AssessmentID:  event.AssessmentID,
        TesteeID:      event.TesteeID,
        TotalScore:    result.TotalScore,
        RiskLevel:     result.RiskLevel,
        FactorScores:  mapToFactorScoreDTOs(result.FactorScores),
        InterpretedAt: time.Now(),
        Duration:      duration,
    })
    
    c.logger.Info("evaluation completed",
        zap.Int64("assessment_id", event.AssessmentID),
        zap.Int64("duration_ms", duration))
    
    return nil
}
```

### 3.3 错误处理与重试

**重试策略**：

| 错误类型 | 重试次数 | 退避策略 | 示例 |
|---------|---------|---------|------|
| 网络超时 | 3 | 指数退避（30s, 1m, 5m） | MongoDB 连接超时 |
| 临时故障 | 3 | 线性退避（30s, 30s, 30s） | MySQL 死锁 |
| 数据错误 | 0 | 不重试，记录日志 | AnswerSheet 损坏 |
| 业务逻辑错误 | 0 | 不重试，标记失败 | 量表规则配置错误 |

**死信队列（DLQ）**：

```go
// 超过最大重试次数后进入死信队列
if msg.Attempts >= 3 {
    c.dlqRepo.Save(ctx, DeadLetterMessage{
        Topic:        "assessment_events",
        MessageBody:  msg.Body,
        ErrorMessage: err.Error(),
        Attempts:     msg.Attempts,
        CreatedAt:    time.Now(),
    })
    
    // 通知运维人员
    c.alertSender.Send(Alert{
        Level:   "warning",
        Message: fmt.Sprintf("Assessment %d evaluation failed after 3 attempts", event.AssessmentID),
    })
    
    return nil // 确认消息，不再重试
}
```

---

## 4. 缓存策略

### 4.1 缓存架构

```
                    [客户端请求]
                          ↓
                  [qs-apiserver]
                          ↓
            ┌─────────────┴─────────────┐
            ↓                           ↓
    [L1: 本地内存缓存]          [L2: Redis 缓存]
    - 热点量表配置              - Assessment 状态
    - 常用问卷模板              - 解析结果摘要
    - 用户 Session              - Testee 基本信息
            ↓                           ↓
            └─────────────┬─────────────┘
                          ↓
                    [持久层：MySQL/MongoDB]
```

### 4.2 状态缓存设计（Phase 2 优化）

**接口抽象**：

```go
// StatusCache Assessment 状态缓存接口
type StatusCache interface {
    // 获取状态摘要
    Get(ctx context.Context, assessmentID int64) (*StatusSummary, error)
    
    // 设置状态摘要
    Set(ctx context.Context, assessmentID int64, summary *StatusSummary, ttl time.Duration) error
    
    // 删除缓存
    Delete(ctx context.Context, assessmentID int64) error
    
    // 批量获取
    MGet(ctx context.Context, assessmentIDs []int64) (map[int64]*StatusSummary, error)
}

// StatusSummary 状态摘要
type StatusSummary struct {
    Status     string   `json:"status"`              // pending/submitted/interpreted/failed
    TotalScore *float64 `json:"total_score,omitempty"`
    RiskLevel  *string  `json:"risk_level,omitempty"`
    UpdatedAt  int64    `json:"updated_at"`          // Unix timestamp
}
```

**Redis 实现**：

```go
type RedisStatusCache struct {
    client *redis.Client
}

func (c *RedisStatusCache) Get(ctx context.Context, assessmentID int64) (*StatusSummary, error) {
    key := fmt.Sprintf("assessment:status:%d", assessmentID)
    
    data, err := c.client.Get(ctx, key).Result()
    if err == redis.Nil {
        return nil, ErrCacheNotFound
    }
    if err != nil {
        return nil, err
    }
    
    var summary StatusSummary
    if err := json.Unmarshal([]byte(data), &summary); err != nil {
        return nil, err
    }
    
    return &summary, nil
}

func (c *RedisStatusCache) Set(ctx context.Context, assessmentID int64, summary *StatusSummary, ttl time.Duration) error {
    key := fmt.Sprintf("assessment:status:%d", assessmentID)
    summary.UpdatedAt = time.Now().Unix()
    
    data, err := json.Marshal(summary)
    if err != nil {
        return err
    }
    
    return c.client.Set(ctx, key, data, ttl).Err()
}
```

**缓存更新策略**：

```go
// 提交时写入"解析中"状态
func (s *AssessmentService) Submit(ctx context.Context, req SubmitRequest) error {
    // ... 业务逻辑 ...
    
    // 写缓存
    if s.statusCache != nil {
        s.statusCache.Set(ctx, assessment.ID, &StatusSummary{
            Status: "submitted",
        }, 30*time.Minute)  // TTL 30分钟
    }
    
    return nil
}

// worker 完成评估后更新为"已解析"
func (w *EvaluationWorker) Handle(event AssessmentSubmittedEvent) error {
    // ... 评估逻辑 ...
    
    // 更新缓存
    if w.statusCache != nil {
        w.statusCache.Set(ctx, assessment.ID, &StatusSummary{
            Status:     "interpreted",
            TotalScore: &result.TotalScore,
            RiskLevel:  &result.RiskLevel,
        }, 2*time.Hour)  // 已完成的缓存更久
    }
    
    return nil
}
```

### 4.3 缓存失效策略

**TTL 设置**：

| 数据类型 | TTL | 理由 |
|---------|-----|------|
| 解析中状态 | 30分钟 | 大部分评估在3秒内完成，30分钟足够兜底 |
| 已解析状态 | 2小时 | 用户可能反复查看报告 |
| 量表配置 | 24小时 | 几乎不变，长期缓存 |
| 用户Session | 30分钟 | 跟随认证系统 TTL |

**缓存预热**：

```go
// 系统启动时预加载热点量表
func (s *ScaleService) WarmupCache(ctx context.Context) error {
    hotScaleIDs := []int64{1, 2, 3, 5, 8}  // SDS, SAS, Conners 等常用量表
    
    for _, id := range hotScaleIDs {
        scale, _ := s.repo.FindByID(ctx, id)
        s.cache.Set(ctx, fmt.Sprintf("scale:%d", id), scale, 24*time.Hour)
    }
    
    return nil
}
```

---

## 5. 查询优化：短轮询到长轮询演进

### 5.1 Phase 1：短轮询 + MySQL 主键查（当前方案）

**适用场景**：
- 总 QPS < 500
- 同时等待解析用户 < 500 人
- 成本优先、架构简单

**实现**：

```go
// GET /api/v1/assessments/:id/status
func (h *AssessmentHandler) GetStatus(c *gin.Context) {
    assessmentID := parseID(c.Param("id"))
    ctx := c.Request.Context()
    
    // 直接查 MySQL，主键查询，< 5ms
    assessment, err := h.repo.FindByID(ctx, assessmentID)
    if err != nil {
        c.JSON(404, gin.H{"error": "assessment not found"})
        return
    }
    
    c.JSON(200, StatusResponse{
        Status:     assessment.Status,
        TotalScore: assessment.TotalScore,
        RiskLevel:  assessment.RiskLevel,
    })
}
```

**前端轮询**：

```javascript
async function pollStatus(assessmentId) {
    const maxAttempts = 30;  // 最多轮询30次
    const interval = 2000;    // 每2秒一次
    
    for (let i = 0; i < maxAttempts; i++) {
        const resp = await fetch(`/api/v1/assessments/${assessmentId}/status`);
        const data = await resp.json();
        
        if (data.status === 'interpreted') {
            // 跳转到报告页
            wx.navigateTo({ url: `/pages/report?id=${assessmentId}` });
            return;
        }
        
        if (data.status === 'failed') {
            wx.showToast({ title: '评估失败，请稍后重试', icon: 'none' });
            return;
        }
        
        await sleep(interval);
    }
    
    wx.showToast({ title: '评估超时，请刷新重试', icon: 'none' });
}
```

**性能分析**：

假设：
- 500 人同时等待
- 每人每 2 秒轮询一次
- QPS = 500 / 2 = **250 QPS**

MySQL 2C4G RDS 可轻松支撑 5000+ QPS 的主键读，**该方案完全够用**。

### 5.2 Phase 2：Redis 缓存 + 读写分离（演进）

**触发条件**：
- /status QPS > 1000
- MySQL 慢查询日志出现 status 查询
- CPU 使用率持续 > 70%

**架构调整**：

```go
func (h *AssessmentHandler) GetStatus(c *gin.Context) {
    assessmentID := parseID(c.Param("id"))
    ctx := c.Request.Context()
    
    // 1. 先查 Redis
    if summary, err := h.statusCache.Get(ctx, assessmentID); err == nil {
        c.JSON(200, StatusResponse{
            Status:     summary.Status,
            TotalScore: summary.TotalScore,
            RiskLevel:  summary.RiskLevel,
        })
        return
    }
    
    // 2. Redis miss，回源 MySQL
    assessment, err := h.repo.FindByID(ctx, assessmentID)
    if err != nil {
        c.JSON(404, gin.H{"error": "assessment not found"})
        return
    }
    
    // 3. 回填缓存
    h.statusCache.Set(ctx, assessmentID, &StatusSummary{
        Status:     assessment.Status,
        TotalScore: assessment.TotalScore,
        RiskLevel:  assessment.RiskLevel,
    }, 30*time.Minute)
    
    c.JSON(200, StatusResponse{
        Status:     assessment.Status,
        TotalScore: assessment.TotalScore,
        RiskLevel:  assessment.RiskLevel,
    })
}
```

**性能提升**：
- Redis 命中率 > 95%（大部分请求在解析中，命中缓存）
- Redis QPS 可达数万
- MySQL 压力下降 **90%+**

### 5.3 Phase 3：长轮询（未来演进）

**适用场景**：
- /status QPS > 5000
- 需要更好的用户体验（实时性）
- 愿意接受更复杂的架构

**实现思路**：

```go
// GET /api/v1/assessments/:id/wait-report?timeout=15
func (h *AssessmentHandler) WaitReport(c *gin.Context) {
    assessmentID := parseID(c.Param("id"))
    timeout := parseDuration(c.Query("timeout"), 15*time.Second)
    
    ctx, cancel := context.WithTimeout(c.Request.Context(), timeout)
    defer cancel()
    
    // 1. 快速检查一次缓存
    if summary, _ := h.statusCache.Get(ctx, assessmentID); summary != nil && summary.Status == "interpreted" {
        c.JSON(200, summary)
        return
    }
    
    // 2. 注册到等待队列
    ch := make(chan StatusSummary, 1)
    h.waiterRegistry.Add(assessmentID, ch)
    defer h.waiterRegistry.Remove(assessmentID, ch)
    
    // 3. 等待三种情况
    ticker := time.NewTicker(1 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            // 超时或客户端断开
            c.JSON(200, StatusResponse{Status: "pending"})
            return
            
        case summary := <-ch:
            // 收到解读完成通知（由 worker 推送）
            c.JSON(200, summary)
            return
            
        case <-ticker.C:
            // 定期轮询缓存（兜底）
            if summary, _ := h.statusCache.Get(ctx, assessmentID); summary != nil && summary.Status == "interpreted" {
                c.JSON(200, summary)
                return
            }
        }
    }
}
```

**通知机制**：

```go
// worker 完成评估后唤醒所有等待的长轮询请求
func (w *EvaluationWorker) Handle(event AssessmentSubmittedEvent) error {
    // ... 评估逻辑 ...
    
    // 通知等待队列
    w.waiterRegistry.Notify(assessment.ID, StatusSummary{
        Status:     "interpreted",
        TotalScore: &result.TotalScore,
        RiskLevel:  &result.RiskLevel,
    })
    
    return nil
}

// WaiterRegistry 实现
type WaiterRegistry struct {
    mu      sync.RWMutex
    waiters map[int64][]chan StatusSummary
}

func (r *WaiterRegistry) Notify(assessmentID int64, summary StatusSummary) {
    r.mu.Lock()
    defer r.mu.Unlock()
    
    channels, ok := r.waiters[assessmentID]
    if !ok {
        return
    }
    
    // 非阻塞写入所有等待的 channel
    for _, ch := range channels {
        select {
        case ch <- summary:
        default:
            // channel 已满或已关闭，跳过
        }
    }
    
    // 清理
    delete(r.waiters, assessmentID)
}
```

**资源消耗**：
- 5000 个并发长轮询 = 5000 个 goroutine
- 内存占用：约 160-320 MB
- TCP 连接：5000 个（需设置 `ulimit -n 65535`）
- CPU：极低（大部分时间阻塞在 select）

**结论**：对于 Go 服务，几千并发长轮询完全可行。

---

## 6. 消息队列在高并发中的作用

### 6.1 削峰填谷

**场景**：入校筛查项目，短时间 500 个提交请求涌入。

**无 MQ 情况**：
```
500 个提交 → 500 个同步评估 → 数据库连接池耗尽 → 部分请求超时失败
```

**有 MQ 情况**：
```
500 个提交 → 立即成功（只写数据库 + 发消息）
    ↓
消息进入队列缓冲
    ↓
worker 按自己节奏消费（50 msg/s）
    ↓
10 秒内全部处理完，无超时
```

### 6.2 弹性伸缩

**动态扩容**：

```yaml
# Kubernetes Deployment 示例
apiVersion: apps/v1
kind: Deployment
metadata:
  name: qs-worker
spec:
  replicas: 3  # 基准 3 个实例
  template:
    spec:
      containers:
      - name: qs-worker
        image: qs-worker:v2.0
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 1Gi
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: qs-worker-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: qs-worker
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: External
    external:
      metric:
        name: nsq_queue_depth
      target:
        type: AverageValue
        averageValue: "100"  # 队列深度超过 100 时扩容
```

### 6.3 容错与重试

**重试机制**：

```go
func (c *Consumer) handleMessage(msg *nsq.Message) error {
    err := c.handler.Handle(msg)
    
    if err == nil {
        return nil  // 成功，ACK
    }
    
    // 判断是否可重试
    if isRetryable(err) && msg.Attempts < 3 {
        return err  // 返回错误，触发 NSQ 重试
    }
    
    // 不可重试或超过最大次数
    c.sendToDLQ(msg, err)
    return nil  // ACK，防止无限重试
}
```

**监控指标**：

| 指标 | 正常值 | 告警阈值 |
|------|--------|---------|
| 队列深度 | < 100 | > 500 |
| 消费速率 | ≈ 生产速率 | < 50% 生产速率 |
| 失败率 | < 0.5% | > 5% |
| 平均延迟 | < 2s | > 10s |

---

## 7. 容量规划与扩展

### 7.1 Phase 1 配置（200 QPS）

**单机部署**：
- **服务器**：2C4G ECS
- **部署内容**：
  - iam-apiserver
  - qs-apiserver
  - qs-collectionserver
  - qs-worker
  - MongoDB
  - Redis-cache
  - NSQ

**资源分配**：
```
Go 服务（4个进程）：  600 MB
MongoDB：            500 MB
Redis-cache：        100 MB
NSQ：                 50 MB
系统保留：           500 MB
----------------------------
总计：              1.75 GB（在 4GB 内舒适运行）
```

**成本**：约 ¥100/月

### 7.2 Phase 2 配置（1000 QPS）

**服务拆分**：

```
┌─────────────────────┐
│  ServerA (4C8G)     │
│  ├─ qs-apiserver   │
│  ├─ collection     │
│  ├─ MongoDB        │
│  └─ Redis-cache    │
└─────────────────────┘
           ↓
    [Cloud MQ (NSQ)]
           ↓
┌─────────────────────┐
│  ServerB (2C4G)     │
│  └─ qs-worker (x3)  │
└─────────────────────┘
           ↓
    [MySQL RDS 4C8G]
    [Redis 2GB]
```

**成本**：约 ¥800/月

### 7.3 Phase 3 配置（5000+ QPS）

**多地域部署**：

```
          [CDN / Global Load Balancer]
                      ↓
    ┌─────────────────┴─────────────────┐
    ↓                                   ↓
[华东区]                            [华北区]
  ├─ API Server (x3)                  ├─ API Server (x3)
  ├─ Collection Server (x2)           ├─ Collection Server (x2)
  └─ Worker (x5)                      └─ Worker (x5)
    ↓                                   ↓
[Redis Cluster]                     [Redis Cluster]
    ↓                                   ↓
    └────────────────┬──────────────────┘
                     ↓
        [MySQL RDS (读写分离 + 跨区同步)]
```

**成本**：约 ¥5000/月

---

## 8. 监控与告警

### 8.1 关键指标

#### API 层
- **请求指标**：
  - QPS（按接口拆分）
  - 响应时间（P50/P95/P99）
  - 错误率（4xx/5xx）
  - 慢请求占比（> 1s）

- **业务指标**：
  - 提交成功率
  - 评估成功率
  - 平均评估耗时

#### Worker 层
- **队列指标**：
  - 队列深度（待处理消息数）
  - 消费速率（msg/s）
  - 消费延迟（消息产生到消费的时间差）

- **处理指标**：
  - 评估耗时分布
  - 失败率与重试次数
  - worker 实例数

#### 缓存层
- **Redis 指标**：
  - 命中率
  - QPS
  - 内存使用率
  - 慢查询

- **本地缓存**：
  - 命中率
  - 内存占用

#### 数据库层
- **MySQL**：
  - QPS（读/写分离）
  - 慢查询日志
  - 连接池使用率
  - 磁盘 I/O

- **MongoDB**：
  - 查询耗时
  - 集合大小
  - 索引使用情况

### 8.2 告警规则

```yaml
alerts:
  - name: HighErrorRate
    condition: api_error_rate > 5%
    duration: 5m
    severity: P1
    notification: [oncall, ops-group]
    
  - name: QueueBacklog
    condition: nsq_queue_depth > 500
    duration: 3m
    severity: P2
    notification: [ops-group]
    
  - name: EvaluationSlow
    condition: evaluation_p95_duration > 10s
    duration: 5m
    severity: P2
    notification: [dev-group]
    
  - name: CacheHitRateLow
    condition: redis_hit_rate < 80%
    duration: 10m
    severity: P3
    notification: [dev-group]
    
  - name: DatabaseCPUHigh
    condition: mysql_cpu_usage > 80%
    duration: 5m
    severity: P1
    notification: [oncall, ops-group]
```

### 8.3 链路追踪

**OpenTelemetry 集成**：

```go
import (
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/trace"
)

func (h *AssessmentHandler) Submit(c *gin.Context) {
    ctx := c.Request.Context()
    tracer := otel.Tracer("qs-apiserver")
    
    ctx, span := tracer.Start(ctx, "assessment.submit")
    defer span.End()
    
    // 1. 校验
    ctx, validationSpan := tracer.Start(ctx, "assessment.validate")
    err := h.validator.Validate(ctx, req)
    validationSpan.End()
    
    // 2. 保存
    ctx, saveSpan := tracer.Start(ctx, "assessment.save")
    err = h.repo.Save(ctx, assessment)
    saveSpan.End()
    
    // 3. 发布事件
    ctx, publishSpan := tracer.Start(ctx, "assessment.publish_event")
    err = h.eventBus.Publish(ctx, "assessment_events", event)
    publishSpan.End()
    
    c.JSON(202, gin.H{"id": assessment.ID})
}
```

**Trace 示例**：

```
Trace ID: 7f8a9b2c4d5e6f1a
├─ POST /api/v1/assessments/submit [250ms]
│  ├─ assessment.validate [5ms]
│  ├─ assessment.save [30ms]
│  │  ├─ mongodb.insert [20ms]
│  │  └─ mysql.insert [10ms]
│  └─ assessment.publish_event [2ms]
│
└─ nsq.consumer.evaluation [2.8s]
   ├─ load.questionnaire [10ms]
   ├─ load.scale [8ms]
   ├─ evaluator.evaluate [2.5s]
   │  ├─ raw_score_step [500ms]
   │  ├─ factor_score_step [800ms]
   │  └─ interpret_step [1.2s]
   └─ save.report [30ms]
```

---

## 9. 总结

### 9.1 设计要点回顾

1. **事件驱动架构**：
   - 通过领域事件实现服务解耦
   - 消息队列提供削峰、容错、重试能力

2. **异步评估**：
   - 提交即返回，避免阻塞用户
   - worker 独立处理，可水平扩展

3. **缓存策略**：
   - Phase 1：无缓存，MySQL 直查（够用）
   - Phase 2：Redis 状态缓存（演进）
   - Phase 3：本地缓存 + Redis 两级缓存

4. **查询优化**：
   - 从短轮询起步（简单）
   - 演进到 Redis 缓存（降压）
   - 未来可升级到长轮询/WebSocket（体验）

5. **渐进演进**：
   - 先满足当前需求（200 QPS）
   - 预留扩展接口（Cache/EventBus）
   - 监控驱动优化（数据说话）

### 9.2 演进路线图

```
当前 Phase 1              中期 Phase 2              远期 Phase 3
───────────────────  →   ────────────────────  →   ────────────────────
• 单机部署               • 服务拆分                • 多地域部署
• 短轮询 + MySQL         • Redis 状态缓存          • 长轮询/WebSocket
• 同步/异步混合          • 完全异步                • 流式处理
• 200 QPS                • 1000 QPS                • 5000+ QPS
• 成本 ¥100/月           • 成本 ¥800/月            • 成本 ¥5000/月
```

### 9.3 关键原则

**KISS（Keep It Simple, Stupid）**：
- 不在 200 QPS 时就搞 Redis 集群
- 不在无压力时就上长轮询
- 不在单机够用时就拆微服务

**YAGNI（You Aren't Gonna Need It）**：
- 不提前实现未来可能需要的功能
- 但要预留清晰的扩展接口

**Measure Before Optimize**：
- 监控先行，用数据说话
- 压测验证瓶颈，不靠猜测
- 每次演进有明确的触发条件

---

## 附录

### A. 相关文档

- 《11-01-问卷&量表BC领域模型总览-v2.md》：领域模型设计
- 《12-03-评估工作流与qs-worker设计-v2.md》：评估流程详细设计
- 《10-Redis消息队列实现.md》：NSQ/Redis MQ 技术细节
- 《02-01-基于六边形架构的模块化设计.md》：代码结构规范

### B. 性能测试报告（模板）

```markdown
# 性能测试报告

## 测试环境
- 服务器：2C4G ECS
- 数据库：RDS 2C4G
- 测试工具：wrk / JMeter
- 并发用户：100 / 500 / 1000

## 测试场景
1. 答卷提交：POST /api/v1/assessments/submit
2. 状态查询：GET /api/v1/assessments/:id/status
3. 报告查询：GET /api/v1/reports/:id

## 测试结果
| 接口 | 并发 | QPS | P50 | P95 | P99 | 错误率 |
|------|------|-----|-----|-----|-----|--------|
| submit | 100 | 180 | 50ms | 120ms | 200ms | 0.1% |
| status | 500 | 450 | 5ms | 15ms | 30ms | 0% |
| report | 100 | 120 | 80ms | 200ms | 350ms | 0% |

## 瓶颈分析
- MongoDB 写入成为瓶颈（提交接口）
- 考虑增加索引或调整写策略

## 优化建议
1. 为 AnswerSheet 创建复合索引
2. 增加 Redis 缓存 status 接口
3. 考虑使用批量写入
```

### C. 压测脚本示例

```bash
#!/bin/bash
# wrk 压测脚本

# 答卷提交
wrk -t 4 -c 100 -d 30s \
    -s submit.lua \
    http://localhost:8080/api/v1/assessments/submit

# 状态查询
wrk -t 4 -c 500 -d 30s \
    http://localhost:8080/api/v1/assessments/123/status
```

```lua
-- submit.lua
wrk.method = "POST"
wrk.headers["Content-Type"] = "application/json"
wrk.headers["Authorization"] = "Bearer xxx"

counter = 1

request = function()
    counter = counter + 1
    body = string.format([[{
        "questionnaire_id": 1,
        "testee_id": %d,
        "answers": {"Q1": "A", "Q2": "B"}
    }]], counter)
    return wrk.format("POST", wrk.path, wrk.headers, body)
end
```

---

**文档版本历史**：
- V1.0 (2025-11-15)：初稿，基于 V1 架构讨论内容
- V2.0 (2025-11-20)：全面重构，结合 V2 领域模型，整合高并发、缓存、事件驱动三大主题

**维护者**：架构组 / 后端团队  
**审阅者**：技术委员会  
**下次评审**：2026-01-01
